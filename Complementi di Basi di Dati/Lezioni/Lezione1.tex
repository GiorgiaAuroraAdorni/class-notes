\section{Introduzione}
I database non consistono solo in dati e tabelle: sono modelli centralizzati o distribuiti che permettono di gestire un carico anche significativo di utenti. La sicurezza è un aspetto importante, insieme all'affidabilità: i sistemi relazionali hanno grandi utilizzi nei settori bancari, e le operazioni devono giungere a termine senza guasti.

I DBMS sono quindi sistemi che devono garantire la gestione di dati di grandi dimensioni, persistenti, affidabili e condivisi. Oltre ai modelli relazionali esistono i NoSQL (Not Only SQL) e RDF, i quali hanno vantaggi e svantaggi a seconda dell'utilizzo.

Per garantire le precedenti caratteristiche, l'architettura di un DBMS deve avere una serie di funzionalità cooperanti, come un gestore delle transazioni, un query compiler e un gestore della memoria secondaria.

\section{Strutture fisiche di accesso}
La più piccola struttura di memorizzazione dei dati a cui gli utenti possano accedere è il file: così come le tabelle, ha un'intestazione fissa e un numero di righe.

I dati non devono solo essere memorizzati in modo persistente: devono anche essere facilmente recuperabili, e gli accessi da gestire sono sia in lettura che in scrittura. Un obiettivo fondamentale è la minnimizzazione del tempo di accesso e trasferimento da CPU alla memoria secondaria.

I dati sono memorizzati nei dischi magnetici, con blocchi da 4-32kbyte e un tempo di accesso di circa $10^{-8}$ millisecondi, con un tasso di trasferimento di 300 Mbit/secondo. Il problema è la grande differenza di ordini di grandezza tra queste operazioni.

L'organizzazione ottimale è un compromesso tra il tempo e lo spazio, di cui il tempo è la priorità considerando il costo ridotto della memoria. 

\subsection{Campi in SQL}
Ogni campo in una tabella è memorizzato in una struttura fisica, ma lo spazio occupato cambia a seconda del tipo del dato. Le tuple sono pertanto record fisici organizzati in collezioni all'interno dei blocchi di memoria, e bisogna gestire anche modifica e cancellazione.

Esempi di tipi di dati:
\begin{itemize}
	\item VARCHAR, che alloca $n + 1$ bytes secondo un bit di carattere separatore o numero di caratteri;
	\item BLOB e GLOB, destinati a larghi file il cui spazio viene allocato solo al momento dell'inserimento.
\end{itemize}

I record possono avere formato e lunghezza fissi o variabili, con eventuali campi straordinari. Il record layout include informazioni supplementari con schemi o puntatori, lunghezza e timestamp di ultima lettura e scrittura. 

I record sono organizzati in blocchi, unità di memoria trasferite dal disco alla memoria principale. La dimensione è generalmente fissa a $2^n$, di cui solitamente alcuni byte non vengono utilizzati. 

Nel caso in cui la lunghezza sia variabile, lo header contiene anche la lunghezza del record e l'offset (distanza rispetto al byte iniziale) dei campi. I campi fissi sono allocati prima di quelli variabili. 

Alcuni record sono rappresentati in più blocchi, cioè spanned: anche questa informazione è contenuta nell'header, e l'ordinamento è gestito tramite la contiguità fisica o collegamento tra record (modello a grafo, sistemi scalabili). 

\subsection{Strutture di files}
I metodi di accesso sono algoritmi o moduli che forniscono primitive CRUD per ciascuna delle strutture.

Esempi di metodi di accesso sono: 
\begin{itemize}
	\item Strutture sequenziali;
	\item Strutture con accesso calcolato (hash);
	\item Strutture ad albero (indice).
\end{itemize}

L'accesso può essere sequenziale, binario o con indice. Il costo è determinato dallo spazio e dal tempo, ed è solitamente approssimato come il numero di blocchi acceduti. Per sceglere la struttura ottima è necessario distinguere se i file sono statici o dinamici e la frequenza delle operazioni CRUD.

\subsubsection{Sequenziali}
Le strutture sequenziali hanno in comune il mantenimento di un ordinamento fisico in memoria. Esistono organizzazioni per righe o per colonne.

\textbf{Non ordinata}: i nuovi record sono appesi in fondo al file nell'ordine in cui arrivano al DB, e l'ordine di visualizzazione è arbitrario. Il dato non è persistente finchè non viene scritto sul FS, quindi il blocco dev'essere copiato nel buffer e il record aggiunto. \\
La scansione è necessariamente sequenziale, quindi lettura e aggiornamento sono lente, e i record vengono periodicamente riorganizzata per sovrascrivere le cancellazioni.

\textbf{Ordinata}: la posizione fisica è determinata dal campo chiave, e l'ordinamento fisico è l'ordinamento delle chiavi. \\
La ricerca (anche per range) è semplice, ma la creazione impiega più tempo. La cancellazione dipende dallo schema di allocazione, ma richiede riorganizzazione periodica. 

Alcuni metodi per rimediare al tempo di inserimento sono l'append in coda con riordinamento periodico, (accesso logaritmico) oppure l'allocazione al posto di record cancellati. Può essere lasciato spazio libero per uso futuro, o possono esserci file di overflow con linked list.

\subsubsection{OLAP}
OLAP (On Line Analytical Processing) è la raccolta di dati il cui uso primario è per le decisioni organizzative. Un data warehouse è un carico di lavoro subject-oriented, integrato, non volatile e variabile con il tempo. 
	
Le informazioni sono rappresentate tramite un cubo dimensionale di cui gli assi indicano il tempo, i prodotti e i punti vendita. L'organizzazione è gerarchica, in categorie.

Non esiste un metodo generale per la modellazione di un DW: il modello ER dev'essere trasformato ed esteso, i dati devono essere permanenti e sono memorizzati in blocchi contenenti righe vicine tra loro. 

I dati sono salvati colonna per colonna per evitare scansioni multiple in query come COUNT, ma l'inserimento viene effettuato comunque con la riga (strutture row-oriented) che poi viene spostata.

\subsubsection{Hash}
Le tabelle hash permettono l'accesso diretto sulla base del campo chiave, in casi in cui una struttura ad array sarebbe inefficiente perché i possibili valori della chiave sono molti di più di quelli utilizzati.

I record sono organizzati in bucket (blocchi), e la funzione hash, generalmente il modulo, associa a ogni valore della chiave un indirizzo. Lo spazio delle chiavi è più grande dello spazio degli indirizzi (funzione non iniettiva) e ci sono possibilità di collisioni.

Le collisioni vengono gestite tramite tabella di overflow o extensible hashing. La tabella di overflow funziona come bucket aggiuntivo per gli hash duplicati, e l'eventuale spostamento con la cancellazione dei record.

Questo comporta la decisione della grandezza dei bucket e dei file: bisogna tenere in considerazione il numero medio di accessi. La probabilità di overflow cresce con il numero di record e decresce con la dimensione del blocco. 

Con $T$ records e $F$ record per bucket in media, il numero dei bucket $B$ dovrebbe essere $B = T / (0.8 \cdot F)$ per utilizzare il 50-80\% dello spazio disponibile.

Le strutture hash sono efficienti per accesso diretto con il valore della chiave, ma non funzionano per ricerche basate su range o campi diversi. La dimensione dei file non deve subire variazioni significative nel tempo.

L'extensible hashing consente la crescita indefinita della struttura ed elimina l'overflow: essa aumenta dinamicamente con accesso tramite directory, la quale definisce la funzione hash. 

Lo spreco di spazio è limitato, le riorganizzazioni sono solo a livello locale e il tempo di accesso è veloce. La directory va tenuta nella memoria principale.

\subsubsection{Strutture ad albero}
Le strutture ad albero (B-tree) si basano sull'utilizzo di un indice, una struttura ausiliaria per l'accesso efficiente ai record tramite un campo chiave (non necessariamente identificante).

Un indice è un altro file con record contenenti chiave e indirizzo, ordinato secondo i valori della chiave (indice analitico di un libro).






