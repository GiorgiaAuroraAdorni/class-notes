\section{Architettura DBMS e MySQL}
MySQL è un esempio di DBMS che utilizza le strutture fisiche e i metodi di accesso menzionati precedentemente. L'architettura è composta da elementi come query compiler, gestore delle transazoni, gestore del buffer e gestore dei metodi di accesso. 

MySql Pluggable Storage Engine Architecture consente ai DBA di selezionare sistemi di storage diversi, di cui ognuno è specializzato per particolari applicazioni. 

Storage engine disponibili:
\begin{enumerate}
	\item MyISAM, motore default, utilizzato per applicazioni web;
	\item InnoDB, implementa sistemi transazionali e garantisce alcune proprietà ACID;
	\item Memory, memorizza i dati in memoria centrale per migliorare l'accesso;
	\item Merge, supporta l'integrazione in formato MyISAM per considerare più tabelle come un oggetto;
	\item Archive, per archivi di grandi dimensioni poco acceduti;
	\item Federated, per dati distribuiti con un unico schema logico;
	\item Cluster/NDB, per high performances e alta disponibilità.
\end{enumerate}

MyISAM è stato il sistema di storage di default fino alla versione 3.2, non è transazionale: ogni database era una directory e ogni tabella un file. Gestisce record in formato fisso e dinamico (dati variabili), con meccanismo di accesso a matrice. Gli indici sono BTREE, RTREE e FULLTEXT, e la concorrenza è solo a livello di tabella.

InnoDB usa il concetto di tablespace per cui la struttura, la tabella e gli indici sono memorizzati insieme. Sono implementati gli indici BRTEE, e le interrogazioni più frequenti hanno tabelle di hash corrispondenti. Il controllo di concorrenza ha caratteristiche multi-versioning, low-level locking e foreign key constraints.

Memory non prevede memorizzazione in memoria persistente, solo centrale. Supporta indici hash e tree-based.

Il DBA può decidere quale storage engine usare per ogni tabella tramite CREATE TABLE. I vari storage differiscono per funzionalità e per velocità di accesso ai dati. 

\section{Esecuzione e ottimizzazione di query}
L'esecuzione delle query, insieme all'ottimizzazione, sono operazioni di cui si occupano il compiler, i gestori delle interrogazioni, dei metodi d'accesso e del buffer. L'approccio può comportare compilazione e memorizzazione oppure esecuzione diretta dopo la compilazione. 

Tramite statistiche, parsing e calcolo del piano logico e fisico, le tabelle logiche vengono trasformate in strutture fisiche con metodi di accesso alla memoria e vengono implementate su esse le operazioni algebriche.

Il primo step è il parsing: il data catalog effettua un'analisi lessicale, sintattica e semantica usando il dizionario. Le query testuali vengono tradotte in algebra relazionale e trasformate in un query tree. Le foglie corrispondono alle tabelle (strutture dati), e i nodi intermedi sono le operazioni algebriche di selezione, proiezione, join ecc.

Il query tree viene successivamente convertito in un query plan logico (sempre con algebra relazionale) che è ottimizzato rispetto al costo computazionale. A un'interrogazione possono corrispondere diverse espressioni, ma l'ordine delle clausole è rilevante per determinare la più efficiente tra quelle equivalenti.

Esempio: le istruzioni WHERE (selezioni) con operatori logici vengono sempre effettuate prima dei JOIN, essendo quest'ultima molto pesante (prodotto cartesiano), ed è meglio ridurre il numero di tuple coinvolte.

Regole di trasformazione di equivalenza:
\begin{enumerate}
	\item Atomizzazione, una soluzione congiuntiva può essere sostituita da una sequenza di operazioni di selezione individuali;
	\item Commutatività della selezione, interscambiabilità delle clausole;
	\item Commutatività di selezione e prodotto cartesiano;
	\item Commutatività di selezione e proiezione;
	\item Commutatività di proiezione e JOIN;
	\item Equivalenza di prodotto cartesiano e selezione con JOIN;
	\item \textbf{Anticipazione della selezione rispetto al JOIN} (JOIN con tuple filtrate o meno);
	\item Anticipazione della proiezione rispetto al JOIN, sotto opportune condizioni.
\end{enumerate}

La trasformazione pertanto avviene seguendo queste proprietà, e stimando i costi delle operazioni fondamentali per diversi metodi di accesso. Il problema ha generalmente complessità esponenziale ma si ricorre alle metaeuristiche. 

Le informazioni quantitative che vengono prese in considerazione sono per esempio la cardinalità delle relazioni, le dimensione di tuple e valori o il numero di valori distinti. Tutte queste sono memorizzate nel catalogo delle statistiche e aggiornate periodicamente. 

\subsection{Buffer management}
L'implementazione degli operatori relazionali e i metodi di accesso dispongono di un numero (sufficiente) di blocchi o pagine nella memoria principale. Ogni pagina corrisponde a un blocco in memoria secondaria, ed è allocata e gestita nel buffer (non persistente).

Il buffer è organizzato in pagine, con dimensioni multiple rispetto ai blocchi nel file system. Si ha che il rapporto tra il tempo di accesso al FS e quello al buffer è $\geq 10^6$. Vale il principio di località e la valutazione della hit ratio.

Il buffer manager media tutte le richieste di lettura e scrittura dei blocchi. Gli indirizzi vengono tradotti, dal disco al buffer e viceversa, e quelli logici diventano fisici. Il numero di pagine disponibili è un parametro definito in fase di creazione del DB, detto buffer pool.

\subsection{Valutazione dei costi}
I costi si dividono in spazio e tempo. Lo spazio si indica come il costo di utilizzo della memoria principale; il costo di una query in termini di tempo di esecuzione, invece, viene valutato considerando:
\begin{enumerate}
	\item Costi di accesso alla memoria secondaria, per acquisire i dati in memoria centrale e memorizzare i risultati;
	\item Costi di memorizzazione di files intermedi;
	\item Costi di elaborazione.
\end{enumerate}
Il primo fattore è il più importante: si misura con il numero di blocchi caricati nel buffer durante il calcolo delle operazioni, trascurando i costi di memorizzazione (caricamenti dei blocchi su disco).

Il costo dominante, pertanto, è il numero di operazion di I/O, cioè il trasferimento di blocchi dal disco al buffer, che dev'essere minimizzato sfruttando al minimo le $M$ pagine disponibili.

\subsection{Rappresentazione fisica delle tabelle}
\subsubsection{Metodi di accesso ai dati}
La scansione realizza un accesso sequenziale a tutti i record, tramite:
\begin{itemize}
	\item Proiezione su insieme di attributi, senza eliminazione dei duplicati;
	\item Selezione su un predicato semplice del tipo $Ai = v$;
	\item Inserimento, cancellazione e aggiornamento delle tuple accedute durante lo scan.
\end{itemize}

L'ordinamento è il metodo per ordinare i dati in memoria principale. I DBMS non possono caricare tutta la base di dati nel buffer, quindi ordinano separatamente e poi effettuano il merge con lo spazio disponibile.

L'accesso diretto può essere eseguito solo se le strutture fisiche (indici, hash) lo permettono.

\subsubsection{Piano di esecuzione fisico}
Un piano di esecuzione fisico descrive l'implementazione delle operazioni di algebra relazionale. 

La selezione può avere predicati semplici, con congiunzione o disgiunzione di condizione (AND, OR). Quelle semplici vengono svolte utilizzando i metidi di accesso, o la ricarca binaria, ma gli altri casi hanno in più la valutabilità del predicato.

Per valutabilità si intende la selettività, e il coinvolgimento di attributi su cui è definito un indice, che permettono un accesso più efficiente. La selettività è definita come il rapporto tra il numero di record che soddisfano il predicato e il numero totale (relazione).

In altre parole, la selettività è la probabilità che un record soddisfi la condizione su un attributo, assumendo uniformità di distribuzione dei valori. Questo valore viene stimato dal DBMS in base a statistiche raccolte durante l'esecuzione di query. 

L'attributo più selettivo è quello con probabilità minima, e il DBMS ordina i predicati in base alla loro selettività: in questo modo, il totale dei record su cui viene effettuato il controllo diminuisce drasticamente. Normalmente è sufficiente scegliere il primo predicato per avere una query ottimizzata. 

Se qualche predicato non è valutabile durante le operazioni di disgiunzione, è necessario uno scan in cui su ogni n-pla di valuta tutta la selezione disgiuntiva. Altrimenti, si possono anche utilizzare gli indici con eliminazione dei duplicati. 

I due metodi sono più o meno efficienti a seconda di come sono composti i record: quando l'interrogazione è poco selettiva conviene uno scan, perché l'eliminazione dei duplicati è inefficiente.

